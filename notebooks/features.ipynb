{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2ee4fb-4593-4cc9-a5b6-2c5ea8e33fc5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature Extraction\n",
    "\n",
    "---\n",
    "### Pitch Histogram\n",
    "- Serves as an indicator of **vadi**, **samvadi**, and **vivadi** swaras.\n",
    "- Also indicates whether a particular **svara** is **tivra**, **shuddha**, or **komal**.\n",
    "\n",
    "### Pitch Gradient\n",
    "The pitch gradient serves as an indicator of whether a particular svara occurs in the **avarohana**, **arohana**, or both within a **raga**.\n",
    "                                                                                \n",
    "### Pitch Standard Deviation\n",
    "The pitch standard deviation serves as an indicator of **svaras** that exhibit **gamakas** (ornamentations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b14599-0146-422b-9716-f44ccb2c2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 09:25:37.588166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-11 09:25:37.605357: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744356337.619478   11291 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744356337.623930   11291 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744356337.638254   11291 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744356337.638273   11291 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744356337.638274   11291 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744356337.638275   11291 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 09:25:37.643488: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mirdata\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb15a67-ff5e-418a-9b8e-caf2b8c8b018",
   "metadata": {},
   "source": [
    "## Load dataset with mirdata dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c7c93c-1c6e-4a62-9412-3db71dc54f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = '../dataset'\n",
    "dataset_name = 'compmusic_raga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b5dc0-2fd3-458b-9674-118bdaf555f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "dataset = mirdata.initialize(dataset_name, data_home=data_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fba30f-b80d-4dbd-aa26-89a0008aae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.download(force_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6361c5a-f29b-41e2-87d9-2cc6d20071df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = dataset.load_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [12:34<00:00,  1.58s/it]\n",
      "INFO: Success: the dataset is complete and all files are valid.\n",
      "INFO: --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset validation results: ({'tracks': {}}, {'tracks': {}})\n"
     ]
    }
   ],
   "source": [
    "# Check dataset validation and completeness\n",
    "validation = dataset.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13c0cd-fd0c-49fd-ab55-ab6961d581ad",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437e1a85-d2b9-4068-b7a4-8ad768d640ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [29:16<00:00,  3.68s/it] \n"
     ]
    }
   ],
   "source": [
    "X_srutis = list()\n",
    "X_counts = list()\n",
    "X_slopes = list()\n",
    "X_stds = list()\n",
    "y = list()\n",
    "\n",
    "window_length = 4096\n",
    "hop_length = 2048\n",
    "\n",
    "min_sruti = int(np.floor(24 * np.log2(1 / 2)))\n",
    "max_sruti = int(np.ceil(24 * np.log2(4)))\n",
    "all_srutis = np.arange(min_sruti, max_sruti + 1)\n",
    "\n",
    "for track_id, track in tqdm(data.items()):\n",
    "    # Skip hindustani\n",
    "    if track.tradition != 'carnatic':\n",
    "        continue\n",
    "\n",
    "    # Get annotations\n",
    "    tonic = track.tonic_fine_tuned\n",
    "    pitch = track.pitch_post_processed\n",
    "    frequencies = pitch.frequencies\n",
    "\n",
    "    # Get ragam\n",
    "    raga = track.raga\n",
    "\n",
    "    # process frequencies\n",
    "    frequencies = frequencies[frequencies != 0]\n",
    "    frequencies = frequencies[(frequencies >= tonic / 2) & (frequencies <= tonic * 4)]\n",
    "\n",
    "    for i in range(hop_length, len(frequencies) - window_length, hop_length):\n",
    "        curr_frequencies = frequencies[i: i + window_length]\n",
    "\n",
    "        # convert to srutis\n",
    "        srutis = 24 * np.log2(curr_frequencies / tonic)\n",
    "        \n",
    "        #smoothed_srutis = savgol_filter(srutis, window_length=7, polyorder=3)\n",
    "        srutis = np.round(srutis)\n",
    "\n",
    "        # Compute sruti counts\n",
    "        unique_srutis, counts = np.unique(srutis, return_counts=True)\n",
    "        sruti_counts = dict(zip(unique_srutis, counts))\n",
    "        full_sruti_counts = np.array(list({sruti: sruti_counts.get(sruti, 0) for sruti in all_srutis}.values()))\n",
    "        full_sruti_counts = full_sruti_counts / np.max(full_sruti_counts)\n",
    "\n",
    "        # Compute slopes of the pitch track\n",
    "        slopes = np.zeros_like(srutis)\n",
    "        dt = 5\n",
    "        for i in range(dt, len(srutis)):\n",
    "            slopes[i] = (srutis[i] - srutis[i - dt]) / dt\n",
    "\n",
    "        # Get slopes of every sruti\n",
    "        slopes_mapping = dict()\n",
    "        for sruti, slope in zip(srutis, slopes):\n",
    "            if sruti not in slopes_mapping:\n",
    "                slopes_mapping[sruti] = []\n",
    "            slopes_mapping[sruti].append(slope)\n",
    "        for sruti in slopes_mapping:\n",
    "            slopes_mapping[sruti] = np.mean(slopes_mapping[sruti])\n",
    "        full_slopes = np.array(list({sruti: slopes_mapping.get(sruti, 0) for sruti in all_srutis}.values()))\n",
    "\n",
    "        # Compute standard deviations of the pitch track\n",
    "        stds = np.zeros_like(srutis)\n",
    "        dt = 32\n",
    "        for i in range(dt, len(srutis)):\n",
    "            stds[i] = np.std(srutis[i - dt:i])\n",
    "\n",
    "        # Get standard deviations of every sruti\n",
    "        std_mapping = dict()\n",
    "        for sruti, std in zip(srutis, stds):\n",
    "            if sruti not in std_mapping:\n",
    "                std_mapping[sruti] = []\n",
    "            std_mapping[sruti].append(std)\n",
    "        for sruti in std_mapping:\n",
    "            std_mapping[sruti] = np.mean(std_mapping[sruti])\n",
    "        full_stds = np.array(list({sruti: std_mapping.get(sruti, 0) for sruti in all_srutis}.values()))\n",
    "\n",
    "        X_srutis.append(srutis)\n",
    "        X_counts.append(full_sruti_counts)\n",
    "        X_slopes.append(full_slopes)\n",
    "        X_stds.append(full_stds)\n",
    "        y.append(raga)\n",
    "\n",
    "X_srutis = np.array(X_srutis)\n",
    "X_counts = np.array(X_counts)\n",
    "X_slopes = np.array(X_slopes)\n",
    "X_stds = np.array(X_stds)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7d391-aad1-4b59-ab99-b8825ff5c418",
   "metadata": {},
   "source": [
    "## Convert labels to one hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2947be4-a6cc-4033-8acf-5f02eabaa1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ragas = list(set(y))\n",
    "len(all_ragas)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i] = all_ragas.index(y[i])\n",
    "\n",
    "y = to_categorical(y, num_classes=len(all_ragas))\n",
    "all_ragas = np.array(all_ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f616e-4f94-47e9-908b-1287b8901911",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a69e89-1e9d-479d-a9dc-d364cc770c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../dataset/srutis.npy', X_srutis)\n",
    "np.save('../dataset/counts.npy', X_counts)\n",
    "np.save('../dataset/slopes.npy', X_slopes)\n",
    "np.save('../dataset/stds.npy', X_slopes)\n",
    "np.save('../dataset/labels.npy', y)\n",
    "np.save('../dataset/mappings.npy', all_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e60a6-9a46-4609-93ce-d439ccf0e7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
